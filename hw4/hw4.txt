1. 
  (a) Normally, the number of candidate 3-itemsets would be n choose 3 where n is how many different numbers there can be in a transaction.
      Since there are branches in the hash tree for the numbers 1-9 each transaction could contain numbers between 1-9.
      This means the number of candidate 3-itemsets would be 9 choose 3 = 84.

  (b) First we have to find what the possible 3-itemsets could be for the transcation.
      3-itemsets: (1,3,5), (1,3,6), (1,3,8), (1,5,6), (1,5,8), (1,6,8), (3,5,6), (3,5,8), (3,6,8), (5,6,8)
      Leaf nodes:    L5,     L5,      L5,      L4,      L3,      L5,      L11,     L11,     L12,     L8

  (c) Any 3-itemset in the transaction that is contained in a leaf node is a candidate itemset.
      (1,6,8) maps to L5, (1,5,8) maps to L3, (3,5,6) maps to L11, (5,6,8) maps to L8
      The candidate itemsets contained in the transaction are (1,6,8), (1,5,8), (3,5,6), (5,6,8).

2.
  (a) False.  Rule: v not in S. This rule is antimonotic because if you keep adding items to S, 
      one of those items may eventually be v.  
      Example: v = 2, S = {1,4,5} if we add 2 to S then v is in S and the rule is violated.
      

  (b) False.  Rule: V has some items of S.  This rule is antimonotonic.  If you keep adding items to S, some or all of those items
      may be in V.
      Example: V = {2,3}, S = {3,4}, V only has 3 in S but if we add 2 to S then V has all items in S 
      V would be a subset and not a proper subset violating the rule.

  (c) True.  Rule: the average of the items in S are greater than or equal to v.  This can be converted into
      a monotonic rule if the items added to set are larger than v making the average(S) larger than v.

3.
  (a) The attribute that has the highest information gains is selected as the splitting attribute.
      |D| = 12
      Seat Belt: Classes = [yes, no], m = 2, yes = 8/12, no = 4/12
      Info(D) = -8/12*log(8/12) - 4/12*log(4/12) = 0.637
       
      Weather Condition: Classes = [bad,good], m = 2, good = 7/12, bad = 5/12
      Info_wc(D) = 7/12*(-5/12*log(5/12)-2/12*log(2/12)) + 5/12*(-3/12*log(3/12)-2/12*log(2/12)) = .6558
      Gain(wc) = -8/12*log(8/12) - 4/12*log(4/12) - .6558 = -0.019

      Driver's Condition: Classes = [sober, ai], m = 2, sober = 7/12, ai = 5/12
      Info_dc(D) = 7/12*(-5/12*log(5/12)-2/12*log(2/12)) + 5/12(-3/12*log(3/12)-2/12*log(2/12)) = .6558
      Gain(dc) = -8/12*log(8/12) - 4/12*log(4/12) - .6558 = -0.019

      Traffic Violation: Classes = [none, dss, dts, esl], m = 4, none = 3/12, dss = 3/12, dts = 3/12, esl = 3/12
      Info_tv(D) = 3/12*(-2/12*log(2/12)-1/12*log(1/12)) + 3/12(-3/12*log(3/12)) + 3/12(-1/12*log(1/12)-2/12*log(2/12)) + 
                   3/12(-2/12*log(2/12)-1/12*log(1/12)) = .4659
      Gain(tv) = -8/12*log(8/12) - 4/12*log(4/12) - .4659 = .171

      Crash Severity: Classes = [minor, major], m = 2, minor = 4/12, major = 8/12
      Info_cs(D) = 4/12(-4/12*log(4/12)) + 8/12*(-4/12*log(4/12)-4/12*log(4/12)) = .6103
      Gain(cs) = -8/12*log(8/12) - 4/12*log(4/12) - .6103 = 0.026

      Traffic violation has the most information gain so it is selected as the splitting attribute of the first node in the tree.

  (b) Weather Condition: SplitInfo_wc(D) = -7/12*log(7/12) - 5/12*log(5/12) = .679
      GainRatio(wc) = -.019/.679 = -.028

      Driver's Condition: SplitInfo_dc(D) = -7/12*log(7/12) - 5/12*log(5/12) = .679
      GainRatio(dc) = -.019/.679 = -.028

      Traffic Violation: SplitInfo_tv(D) = -3/12*log(3/12) - 3/12*log(3/12) - 3/12*log(3/12) - 3/12*log(3/12) = 1.386
      GainRatio(tv) = .171/1.386 = .123

      Crash Severity: SplitInfo_cs(D) = -4/12*log(4/12) - 8/12*log(8/12) = .637
      GainRatio(cs) = .026/.637 = .041

     Traffic violation has the maximum gain ratio so it is selected as the splitting attribute of the first node in the tree.
     In this case, the first level of the tree is not different from (a).

   (c) Seat Belt: c_1 = yes, c_2 = no
       P(sb=yes) = 8/12
       P(sb=no) = 4/12

       weather condition = bad
       P(wc=bad|yes) = 3/8
       P(wc=bad|no) = 2/4

       driver's condition = sober
       P(dc=sober|yes) = 5/8
       P(dc=sober|no) = 2/4

       traffic violation = none 
       P(tv=none|yes) = 2/8
       P(tv=none|no) = 1/4

       crash serverity = major
       P(cs=major|yes) = 4/8
       P(cs=major|no) = 4/4

       P(X|seat belt = yes) = .375*.625*.25*.5 = .029
       P(X|seat belt = no) = .5*.5*.25*1 = .063

       P(X|seat belt = yes)*P(sb=yes) = .029*.667 = .019
       P(X|seat belt = no)*P(sb=no) = .063*.334 = .021
        
       
       
